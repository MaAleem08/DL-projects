{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlI14gkhiCXN"
      },
      "source": [
        "## LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhi04vYjC-XW",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install pysrt\n",
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtJ4OiGsmtdV"
      },
      "outputs": [],
      "source": [
        "import random , pandas as pd , numpy as np , re , pysrt , tensorflow as tf , gensim , keras_tuner as kt\n",
        "from pathlib import Path\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from tensorflow.keras.models import Sequential ,load_model\n",
        "from tensorflow.keras.layers import  LSTM, Dense , Activation , Embedding, MaxPool1D ,GlobalMaxPool1D , Conv1D , BatchNormalization , InputLayer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrq3cGrfiN8B"
      },
      "source": [
        "## LOADING DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mC2SL1vNmzzO"
      },
      "outputs": [],
      "source": [
        "\n",
        "folder_path = Path(\"/content/\")\n",
        "files = list(folder_path.glob('*'))\n",
        "text = ''\n",
        "\n",
        "\n",
        "for file_ in files:\n",
        "    if str(file_)[-3:] == 'srt' :\n",
        "        print(file_)\n",
        "        subs = pysrt.open(file_)\n",
        "        text_ = '\\n'.join(sub.text for sub in subs)\n",
        "        text = ' '.join([text,text_])\n",
        "\n",
        "print(text)\n",
        "\n",
        "print(type(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qw2Pcb2liXJ9"
      },
      "source": [
        "## PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plU9CVTsm6F9"
      },
      "outputs": [],
      "source": [
        "# Ran the loop twice beacuse treating subtitles of one film creates issues in other film subtiles ,so running twice helps.\n",
        "\n",
        "for i in range(2):\n",
        "    text = text.lower().replace('</i>', '').replace('â™ª', '').replace('<i>', '').replace('...','').replace(',',' ' ).replace('\\'',\"'\").replace('\\n',' ').replace('  ',' ').replace(' - ' , ' ').replace(\"--\",\"\").replace('\"','').replace(\".\",\"\").replace('wwwfacebookcom/englishlolchannel/','')\n",
        "    pattern1 = r'\\[.*?\\]|\\?'\n",
        "    result = re.sub(pattern1, '', text)\n",
        "    pattern2 = r'{.}'\n",
        "    result = re.sub(pattern2, '', result)\n",
        "    pattern3 = r\"(\\w+)'\"\n",
        "    result = re.sub(pattern3,'g',result)\n",
        "    pattern4 = r'<.*?>'\n",
        "    result = re.sub(pattern4,\"\",result)\n",
        "    pattern5 = r'(\\d+)[ ,]+(\\d+)'\n",
        "    result = re.sub(pattern5,\"\",result)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl_WbjW5VlcL"
      },
      "outputs": [],
      "source": [
        "#saving the processed text to have a good look\n",
        "\n",
        "# with open(\"C:/Users/Lenovo/Desktop/next work/lafs.txt\", \"w\") as file:\n",
        "#     file.write(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh1LYLPwjRgj"
      },
      "source": [
        "## tokenizing the texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qlu9Fy2jVlcM"
      },
      "outputs": [],
      "source": [
        "# tokenization\n",
        "tokenizer = RegexpTokenizer(r\"\\S+\")\n",
        "tokens = tokenizer.tokenize(result.lower())\n",
        "print(tokens[:15])\n",
        "\n",
        "print(len(tokens))\n",
        "print(len(np.unique(tokens)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmxBuJv5m4-d"
      },
      "outputs": [],
      "source": [
        "unique_tokens = np.unique(tokens)\n",
        "unique_tokens_index = {token : idx for idx , token in enumerate(unique_tokens)}\n",
        "print(unique_tokens_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FE_z2Ck51_x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKEA2Wpujcad"
      },
      "source": [
        "## creating the input and output words for the model similar to x and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQt1OYa8nHEs"
      },
      "outputs": [],
      "source": [
        "# preparing the data\n",
        "nwords = 20\n",
        "input_words = []\n",
        "next_words = []\n",
        "\n",
        "for i in range(len(tokens)-nwords):\n",
        "    input_words.append(tokens[i : i+nwords])\n",
        "    next_words.append(tokens[i+nwords])\n",
        "\n",
        "print(input_words[69])\n",
        "print(next_words[69])\n",
        "\n",
        "print(len(input_words))\n",
        "print(len(next_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQGwl8fWnGxK"
      },
      "outputs": [],
      "source": [
        "print(input_words[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I02bHfIkRC0"
      },
      "source": [
        "## coming up with X and Y in form of arrays\n",
        "## Replacing all the words with their respective token numbers fro X\n",
        "## creating a sparse categorical for Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WG5NwmBVlcR"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((len(input_words) , nwords , len(unique_tokens)), dtype = 'int32')\n",
        "\n",
        "y = np.zeros((len(next_words),len(unique_tokens)) , dtype='int32')\n",
        "\n",
        "for i, sent_ in enumerate(input_words):\n",
        "  for j,word_ in enumerate(sent_):\n",
        "    x[i,j,unique_tokens_index[word_]] = 1\n",
        "  y[i,unique_tokens_index[next_words[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3jSq97T51_0"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ktung4LYVlcS"
      },
      "outputs": [],
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDRlSsDtVlcT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM_DOlToljUS"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdUhsJZ-DB6K"
      },
      "outputs": [],
      "source": [
        "def tuner_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=(nwords , len(unique_tokens))))\n",
        "\n",
        "    for i in range(hp.Int('num_layers', min_value=1, max_value=9)):\n",
        "\n",
        "        units = hp.Int('units_'+str(i+1), min_value=16, max_value=256, step=16)\n",
        "        activation = hp.Choice('activation_'+str(i+1), values=['relu', 'tanh'])\n",
        "        return_sequences = True\n",
        "\n",
        "        model.add(LSTM(units, activation=activation, return_sequences=return_sequences))\n",
        "\n",
        "        if hp.Boolean('batch_norm_lstm_'+str(i+1)):\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "        if hp.Boolean('max_pooling_lstm_'+str(i+1)):\n",
        "            model.add(GlobalMaxPool1D())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    units = hp.Int('units_'+str(-1), min_value=16, max_value=256, step=16)\n",
        "    activation = hp.Choice('activation_'+str(i-1), values=['relu', 'tanh'])\n",
        "\n",
        "    model.add(LSTM(units, activation=activation, return_sequences=False))\n",
        "\n",
        "    if hp.Boolean('batch_norm_lstm_'+str(i-1)):\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "    if hp.Boolean('max_pooling_lstm_'+str(-1)):\n",
        "            model.add(GlobalMaxPool1D())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(hp.Int('num_layers', min_value=1, max_value=3)):\n",
        "\n",
        "        model.add(Dense(\n",
        "                        units = hp.Int('dense_'+str(i+1), min_value=0, max_value=256, step=32),\n",
        "                        activation = hp.Choice('activation_'+str(i+1), values=['relu', 'tanh']))\n",
        "                       )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model.add(Dense(len(unique_tokens), activation='softmax'))\n",
        "\n",
        "    optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop', 'adagrad', 'adadelta', 'nadam'])\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SHFPyTsmiKz"
      },
      "source": [
        "## now tuning the model using keras tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UXLH0ZMwCcx"
      },
      "outputs": [],
      "source": [
        "\n",
        "tuner = kt.RandomSearch(tuner_model,objective = 'val_accuracy' , max_trials =  5 , directory = 'keras_tuner',project_name=  'tuner_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM-dG_o72ASi"
      },
      "outputs": [],
      "source": [
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss',patience=5, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.1, patience = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7-AG1rNEss9"
      },
      "outputs": [],
      "source": [
        "# lets say the model tuning encounters some error at 2nd epoch , then we need to remove the model tuning that happend till now\n",
        "\n",
        "# !rm -r /content/keras_tuner/tuner_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjmoJTxy2Axn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# tuner.search(x,y,epochs = 5 , validation_split=0.2 ,callbacks = [earlystop,reduce_lr])\n",
        "\n",
        "# some times it happens that the tuning runs for more than 5 epochs for some reasons , so to avoid that we use for loop\n",
        "\n",
        "max_trials = 5\n",
        "\n",
        "for i in range(max_trials):\n",
        "    tuner.search(x, y, epochs=5, validation_split=0.2, callbacks=[earlystop, reduce_lr],batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymQxcEha2Ppm"
      },
      "outputs": [],
      "source": [
        "model1 = tuner.hypermodel.build(tuner.get_best_hyperparameters(num_trials=1)[0])\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzjLnb13CC4j"
      },
      "outputs": [],
      "source": [
        "# saving the best tuned model in case there is any issue like internet disconnection then we can resume from here.\n",
        "\n",
        "# best_model = tuner.get_best_models(num_models=1)[0]\n",
        "# best_model.save('best_model_search.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHilDcIGVfgQ"
      },
      "outputs": [],
      "source": [
        "# downloading the saved best tuned model\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "# files.download('best_model_search.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCJOIga9nmSW"
      },
      "source": [
        "## model fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcJ0EuE52YLe"
      },
      "outputs": [],
      "source": [
        "model1.fit(x,y,epochs = 100 , validation_split=0.2 ,callbacks = [earlystop,reduce_lr], batch_size=128,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-kArrOZWoJw"
      },
      "outputs": [],
      "source": [
        "# model1.save('my_model.h5')\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5o2lyzrt9le"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "\n",
        "# model = load_model('/content/best_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDZYakQDnsqz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q46k-qmnt3P"
      },
      "source": [
        "## making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZTr69qNnXk5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def pred(input_ ,nbest):\n",
        "    input_ = input_.lower()\n",
        "    x = np.zeros((1,nwords,len(unique_tokens)))\n",
        "    for i,word in enumerate(input_.split()):\n",
        "        x[0,i,unique_tokens_index[word]] = 1\n",
        "\n",
        "    predict_ = model.predict(x)[0]\n",
        "    return np.argpartition(predict_ , -nbest)[-nbest:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAPIXAcSnW_Z"
      },
      "outputs": [],
      "source": [
        "pp = pred('probably chose to be four minutes late',5)\n",
        "print([unique_tokens[i] for i in pp])\n",
        "\n",
        "## this gives the predictoins for next 5 words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMzdu02RnVyq"
      },
      "outputs": [],
      "source": [
        "## making predictions for next 100 words\n",
        "\n",
        "\n",
        "def generate_text(input_text , text_length , creativity = 3):\n",
        "    word_seq = input_text.split()\n",
        "    current = 0\n",
        "    for _ in range(text_length):\n",
        "        sub_seq =  \" \".join(tokenizer.tokenize(\" \".join(word_seq).lower())[current:current+nwords])\n",
        "        choice = unique_tokens[random.choice(pred(sub_seq,creativity))]\n",
        "        word_seq.append(choice)\n",
        "        current+=1\n",
        "    return \" \".join(word_seq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ0Kz1WHnffr"
      },
      "outputs": [],
      "source": [
        "\n",
        "generate_text('probably chose to be four minutes late',100,5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m6tjFy2vPpk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWPFg-seuLd1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSLwUGWwuQZh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiK8F538u-aP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSIg5j-nu_wT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj2ZIEnfVlc2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pei3co9_Vlc2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "LCJOIga9nmSW",
        "_q46k-qmnt3P"
      ],
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}