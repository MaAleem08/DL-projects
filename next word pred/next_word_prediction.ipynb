{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LIBRARIES"
      ],
      "metadata": {
        "id": "DlI14gkhiCXN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhi04vYjC-XW"
      },
      "outputs": [],
      "source": [
        "!pip install pysrt\n",
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-XBaytRKn7GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtJ4OiGsmtdV"
      },
      "outputs": [],
      "source": [
        "import random , pandas as pd , numpy as np , re , pysrt , tensorflow as tf , gensim\n",
        "from pathlib import Path\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from tensorflow.keras.models import Sequential ,load_model\n",
        "from tensorflow.keras.layers import  LSTM, Dense , Activation , Embedding, MaxPool1D ,GlobalMaxPool1D , Conv1D , BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOADING DATA"
      ],
      "metadata": {
        "id": "Nrq3cGrfiN8B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mC2SL1vNmzzO",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "folder_path = Path(\"/content/\")\n",
        "files = list(folder_path.glob('*'))\n",
        "text = ''\n",
        "\n",
        "for file_ in files:\n",
        "    if str(file_)[-3:] == 'srt' :\n",
        "        print(file_)\n",
        "        subs = pysrt.open(file_)\n",
        "        text_ = '\\n'.join(sub.text for sub in subs)\n",
        "        text = ' '.join([text,text_])\n",
        "\n",
        "print(text)\n",
        "\n",
        "print(type(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPROCESSING"
      ],
      "metadata": {
        "id": "Qw2Pcb2liXJ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plU9CVTsm6F9"
      },
      "outputs": [],
      "source": [
        "# Ran the loop twice beacuse treating subtitles of one film creates issues in other film subtiles ,so running twice helps.\n",
        "\n",
        "for i in range(2):\n",
        "    text = text.lower().replace('</i>', '').replace('â™ª', '').replace('<i>', '').replace('...','').replace(',',' , ' ).replace('\\'',\"'\").replace('\\n',' ').replace('  ',' ').replace(' - ' , ' ').replace(\"--\",\"\").replace('\"','').replace(\".\",\"\").replace('wwwfacebookcom/englishlolchannel/','')\n",
        "    pattern1 = r'\\[.*?\\]|\\?'\n",
        "    result = re.sub(pattern1, '', text)\n",
        "    pattern2 = r'{.}'\n",
        "    result = re.sub(pattern2, '', result)\n",
        "    pattern3 = r\"(\\w+)'\"\n",
        "    result = re.sub(pattern3,'g',result)\n",
        "    pattern4 = r'<.*?>'\n",
        "    result = re.sub(pattern4,\"\",result)\n",
        "    pattern5 = r'(\\d+)[ ,]+(\\d+)'\n",
        "    result = re.sub(pattern5,\"\",result)\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl_WbjW5VlcL"
      },
      "outputs": [],
      "source": [
        "#saving the processed text to have a good look\n",
        "\n",
        "# with open(\"C:/Users/Lenovo/Desktop/next work/lafs.txt\", \"w\") as file:\n",
        "#     file.write(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenizing the texts"
      ],
      "metadata": {
        "id": "zh1LYLPwjRgj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qlu9Fy2jVlcM"
      },
      "outputs": [],
      "source": [
        "# tokenization\n",
        "tokenizer = RegexpTokenizer(r\"\\S+\")\n",
        "tokens = tokenizer.tokenize(result.lower())\n",
        "print(tokens[:15])\n",
        "\n",
        "print(len(tokens))\n",
        "print(len(np.unique(tokens)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmxBuJv5m4-d"
      },
      "outputs": [],
      "source": [
        "unique_tokens = np.unique(tokens)\n",
        "unique_tokens_index = {token : idx for idx , token in enumerate(unique_tokens)}\n",
        "print(unique_tokens_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating the input and output words for the model similar to x and y"
      ],
      "metadata": {
        "id": "ZKEA2Wpujcad"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQt1OYa8nHEs"
      },
      "outputs": [],
      "source": [
        "# preparing the data\n",
        "nwords = 10\n",
        "input_words = []\n",
        "output_words = []\n",
        "\n",
        "for i in range(len(tokens)-nwords):\n",
        "    input_words.append(tokens[i : i+nwords])\n",
        "    output_words.append(tokens[i+nwords])\n",
        "\n",
        "print(input_words[65])\n",
        "print(output_words[65])\n",
        "\n",
        "print(len(input_words))\n",
        "print(len(output_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQGwl8fWnGxK"
      },
      "outputs": [],
      "source": [
        "print(input_words[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## using gensim to create vectors for each word"
      ],
      "metadata": {
        "id": "s6LNI6Y_js2q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqvK_hZPVlcP"
      },
      "outputs": [],
      "source": [
        "dim = 100\n",
        "wrd2vc = gensim.models.Word2Vec(sentences = input_words , vector_size = dim , window = 10 ,  min_count = 1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40t2M6iDnynD"
      },
      "outputs": [],
      "source": [
        "wrd2vc.wv.most_similar('leave')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## coming up with X and Y in form of arrays\n",
        "## Replacing all the words with their respective token numbers fro X\n",
        "## creating a sparse categorical for Y"
      ],
      "metadata": {
        "id": "_I02bHfIkRC0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WG5NwmBVlcR"
      },
      "outputs": [],
      "source": [
        "x = np.array(input_words)\n",
        "\n",
        "y = np.zeros((len(output_words),len(unique_tokens)))\n",
        "\n",
        "for i in range(len(input_words)):\n",
        "    for j in range(len(input_words[i])):\n",
        "        x[i,j] = unique_tokens_index[x[i,j]]\n",
        "    y[i,unique_tokens_index[output_words[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ktung4LYVlcS"
      },
      "outputs": [],
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating a weight matrix for embedding layer"
      ],
      "metadata": {
        "id": "jZqm4_n8lcfF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QBHboE4VlcS"
      },
      "outputs": [],
      "source": [
        "def wt_matrix(model):\n",
        "  weight_matrix = np.zeros((len(unique_tokens) , dim))\n",
        "\n",
        "  for word_ , ind_ in unique_tokens_index.items():\n",
        "    weight_matrix[ind_] = model.wv[word_]\n",
        "\n",
        "  return weight_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txGZ9heUVlcT"
      },
      "outputs": [],
      "source": [
        "embedded_vectors = wt_matrix(wrd2vc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDRlSsDtVlcT"
      },
      "outputs": [],
      "source": [
        "embedded_vectors.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model\n",
        "## 2 models but doing the same , 1st model is the elaborated version of model 2"
      ],
      "metadata": {
        "id": "RM_DOlToljUS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBywcq6eVlcT"
      },
      "outputs": [],
      "source": [
        "# def tuner_model(hp):\n",
        "\n",
        "#     model = Sequential()\n",
        "#     model.add(Embedding( len(unique_tokens) , output_dim = dim , weights = [embedded_vectors] , trainable = False))\n",
        "\n",
        "\n",
        "#     counter_ = 0\n",
        "\n",
        "#     for i in range(hp.Int('num_layers',min_value=1,max_value=10)):\n",
        "\n",
        "#         if counter_ < 10:\n",
        "#             model.add(\n",
        "#                        LSTM(\n",
        "#                             hp.Int('units'+str(i),min_value = 8 , max_value = 256 , step = 8),\n",
        "#                             activation= hp.Choice('activation'+str(i) , values = ['relu','tanh']),\n",
        "#                             return_sequences = True\n",
        "#                             )\n",
        "#                      )\n",
        "\n",
        "#         else :\n",
        "#             model.add(\n",
        "#                        LSTM(\n",
        "#                             hp.Int('units'+str(i),min_value = 8 , max_value = 256 , step = 8),\n",
        "#                             activation= hp.Choice('activation'+str(i) , values = ['relu','tanh']),\n",
        "#                             return_sequences = False\n",
        "#                             )\n",
        "#                      )\n",
        "\n",
        "#         counter_ += 1\n",
        "\n",
        "\n",
        "#         # Apply Batch Normalization if chosen by the tuner\n",
        "#         if hp.Boolean('batch_norm'+str(i)):\n",
        "#             model.add(BatchNormalization())\n",
        "\n",
        "#         # Apply Max Pooling if chosen by the tuner\n",
        "#         if hp.Boolean('max_pooling'+str(i)):\n",
        "#             model.add(GlobalMaxPool1D())\n",
        "\n",
        "\n",
        "#     model.add(Dense(len(unique_tokens) , activation = 'softmax'))\n",
        "\n",
        "\n",
        "#     model.compile( optimizer = hp.Choice('optimizer',values = ['adam','sgd','rmsprop','adagrad' , 'adadelta', 'nadam']),\n",
        "#                    loss = 'categorical_crossentropy',\n",
        "#                    metrics =['accuracy']\n",
        "#                    )\n",
        "\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mwyoxV5VlcU"
      },
      "outputs": [],
      "source": [
        "def tuner_model(hp):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding( len(unique_tokens) , output_dim = dim , weights = [embedded_vectors] , trainable = False))\n",
        "\n",
        "    for i in range(hp.Int('num_layers',min_value=1,max_value=10)):\n",
        "\n",
        "        units = hp.Int('units_'+str(i),min_value = 8 , max_value = 256 , step = 8)\n",
        "        activation = hp.Choice('activation_'+str(i), values = ['relu','tanh'])\n",
        "        return_sequences = True if i < 10 else False\n",
        "\n",
        "        model.add(LSTM(units, activation=activation, return_sequences=return_sequences))\n",
        "\n",
        "        # using ' IF '   ,  if its prooven beneficial keras_tuner keeps it\n",
        "        if hp.Boolean('batch_norm'+str(i)):\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "        # Apply Max Pooling if chosen by the tuner\n",
        "        if hp.Boolean('max_pooling'+str(i)):\n",
        "            model.add(GlobalMaxPool1D())\n",
        "\n",
        "    model.add(Dense(len(unique_tokens) , activation = 'softmax'))\n",
        "\n",
        "    optimizer = hp.Choice('optimizer', values = ['adam','sgd','rmsprop','adagrad' , 'adadelta', 'nadam'])\n",
        "\n",
        "    model.compile(optimizer = optimizer,\n",
        "                  loss = 'categorical_crossentropy',\n",
        "                  metrics =['accuracy']\n",
        "                  )\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdUhsJZ-DB6K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## now tuning the model using keras tuner"
      ],
      "metadata": {
        "id": "_SHFPyTsmiKz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UXLH0ZMwCcx"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "tuner = kt.Hyperband(tuner_model,objective = 'val_accuracy' , max_epochs =  5 , factor = 3 , directory = 'keras_tuner',project_name=  'tuner_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM-dG_o72ASi"
      },
      "outputs": [],
      "source": [
        "\n",
        "earlystop = EarlyStopping(monitor = 'val_loss',patience=5, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.1, patience = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7-AG1rNEss9"
      },
      "outputs": [],
      "source": [
        "# lets say the model tuning encounters some error at 2nd epoch , then we need to remove the model tuning that happend till now\n",
        "\n",
        "# !rm -r /content/keras_tuner/tuner_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjmoJTxy2Axn"
      },
      "outputs": [],
      "source": [
        "# tuner_.search(x,y,epochs = 5 , validation_split=0.2 ,callbacks = [earlystop,reduce_lr])\n",
        "\n",
        "# some times it happens that the tuning runs for more than 5 epochs for some reasons , so to avoid that we use for loop\n",
        "\n",
        "max_trials = 5\n",
        "\n",
        "for i in range(max_trials):\n",
        "    tuner.search(x, y, epochs=5, validation_split=0.2, callbacks=[earlystop, reduce_lr])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymQxcEha2Ppm"
      },
      "outputs": [],
      "source": [
        "model1 = tuner.hypermodel.build(tuner.get_best_hyperparameters(num_trials=1)[0])\n",
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzjLnb13CC4j"
      },
      "outputs": [],
      "source": [
        "# saving the best tuned model in case there is any issue like internet disconnection then we can resume from here.\n",
        "\n",
        "# best_model = tuner.get_best_models(num_models=1)[0]\n",
        "# best_model.save('best_model_search.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHilDcIGVfgQ"
      },
      "outputs": [],
      "source": [
        "# downloading the saved best tuned model\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "# files.download('best_model_search.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model fitting"
      ],
      "metadata": {
        "id": "LCJOIga9nmSW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcJ0EuE52YLe"
      },
      "outputs": [],
      "source": [
        "model1.fit(x,y,epochs = 100 , validation_split=0.2 ,callbacks = [earlystop,reduce_lr], batch_size=128,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-kArrOZWoJw"
      },
      "outputs": [],
      "source": [
        "# model1.save('my_model.h5')\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5o2lyzrt9le"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "\n",
        "# model = load_model('/content/best_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kDZYakQDnsqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## making predictions"
      ],
      "metadata": {
        "id": "_q46k-qmnt3P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZTr69qNnXk5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def pred(input_ ,nbest):\n",
        "    input_ = input_.lower()\n",
        "    x = np.zeros((1,nwords,len(unique_tokens)))\n",
        "    for i,word in enumerate(input_.split()):\n",
        "        x[0,i,unique_tokens_index[word]] = 1\n",
        "\n",
        "    predict_ = model.predict(x)[0]\n",
        "    return np.argpartition(predict_ , -nbest)[-nbest:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAPIXAcSnW_Z"
      },
      "outputs": [],
      "source": [
        "pp = pred('probably chose to be four minutes late',5)\n",
        "print([unique_tokens[i] for i in pp])\n",
        "\n",
        "## this gives the predictoins for next 5 words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMzdu02RnVyq"
      },
      "outputs": [],
      "source": [
        "## making predictions for next 100 words\n",
        "\n",
        "\n",
        "def generate_text(input_text , text_length , creativity = 3):\n",
        "    word_seq = input_text.split()\n",
        "    current = 0\n",
        "    for _ in range(text_length):\n",
        "        sub_seq =  \" \".join(tokenizer.tokenize(\" \".join(word_seq).lower())[current:current+nwords])\n",
        "        choice = unique_tokens[random.choice(pred(sub_seq,creativity))]\n",
        "        word_seq.append(choice)\n",
        "        current+=1\n",
        "    return \" \".join(word_seq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ0Kz1WHnffr"
      },
      "outputs": [],
      "source": [
        "\n",
        "generate_text('probably chose to be four minutes late',100,5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m6tjFy2vPpk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWPFg-seuLd1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSLwUGWwuQZh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiK8F538u-aP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSIg5j-nu_wT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj2ZIEnfVlc2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pei3co9_Vlc2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "DlI14gkhiCXN",
        "Nrq3cGrfiN8B",
        "Qw2Pcb2liXJ9",
        "zh1LYLPwjRgj",
        "ZKEA2Wpujcad",
        "s6LNI6Y_js2q",
        "_I02bHfIkRC0",
        "jZqm4_n8lcfF",
        "RM_DOlToljUS",
        "_SHFPyTsmiKz",
        "LCJOIga9nmSW",
        "_q46k-qmnt3P"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}